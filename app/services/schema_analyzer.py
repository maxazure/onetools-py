"""è¡¨ç»“æ„åˆ†æå™¨ - åˆ†æSQLè¯­å¥ä¸­çš„è¡¨/è§†å›¾ç»“æ„"""

import re
import asyncio
from typing import Dict, List, Set, Optional, Any, Tuple
from dataclasses import dataclass

from app.core.database import get_sqlserver_manager
from app.core.logging import LoggerMixin


@dataclass
class TableInfo:
    """è¡¨/è§†å›¾ä¿¡æ¯"""
    name: str
    schema: str
    database: str
    full_name: str
    object_type: str  # 'TABLE' or 'VIEW'
    columns: List[Dict[str, Any]]
    view_definition: Optional[str] = None
    referenced_tables: Optional[Set[str]] = None


@dataclass
class SchemaAnalysisResult:
    """è¡¨ç»“æ„åˆ†æç»“æœ"""
    tables: List[TableInfo]
    views: List[TableInfo]
    all_referenced_tables: Set[str]
    formatted_output: str
    analysis_summary: str


class SchemaAnalyzer(LoggerMixin):
    """è¡¨ç»“æ„åˆ†æå™¨ - åˆ†æSQLè¯­å¥ä¸­åŒ…å«çš„æ‰€æœ‰è¡¨å’Œè§†å›¾çš„ç»“æ„"""
    
    def __init__(self):
        super().__init__()
        self.sqlserver = get_sqlserver_manager()
        self._analyzed_objects: Set[str] = set()  # é˜²æ­¢å¾ªç¯åˆ†æ
        
    async def analyze_sql_schema(self, sql: str, server_name: Optional[str] = None) -> SchemaAnalysisResult:
        """åˆ†æSQLè¯­å¥ä¸­çš„è¡¨ç»“æ„"""
        try:
            self.log_info("å¼€å§‹åˆ†æSQLè¯­å¥ä¸­çš„è¡¨ç»“æ„")
            
            # é‡ç½®çŠ¶æ€
            self._analyzed_objects.clear()
            
            # 1. æå–SQLä¸­çš„è¡¨åå’Œè§†å›¾å
            table_references = self._extract_table_references(sql)
            
            if not table_references:
                return SchemaAnalysisResult(
                    tables=[],
                    views=[],
                    all_referenced_tables=set(),
                    formatted_output="æœªæ‰¾åˆ°ä»»ä½•è¡¨æˆ–è§†å›¾å¼•ç”¨",
                    analysis_summary="SQLè¯­å¥ä¸­æœªåŒ…å«è¡¨æˆ–è§†å›¾å¼•ç”¨"
                )
            
            # 2. è·å–æ‰€æœ‰è¡¨å’Œè§†å›¾çš„è¯¦ç»†ä¿¡æ¯
            tables = []
            views = []
            all_referenced_tables = set()
            
            for table_ref in table_references:
                table_info = await self._get_table_info(table_ref, server_name)
                if table_info:
                    all_referenced_tables.add(table_info.full_name)
                    
                    if table_info.object_type == 'TABLE':
                        tables.append(table_info)
                    elif table_info.object_type == 'VIEW':
                        views.append(table_info)
                        
                        # 3. é€’å½’åˆ†æè§†å›¾å†…çš„è¡¨
                        if table_info.view_definition:
                            nested_tables = await self._analyze_view_dependencies(
                                table_info.view_definition, 
                                server_name
                            )
                            for nested_table in nested_tables:
                                all_referenced_tables.add(nested_table.full_name)
                                if nested_table.object_type == 'TABLE':
                                    # é¿å…é‡å¤æ·»åŠ 
                                    if not any(t.full_name == nested_table.full_name for t in tables):
                                        tables.append(nested_table)
                                elif nested_table.object_type == 'VIEW':
                                    if not any(v.full_name == nested_table.full_name for v in views):
                                        views.append(nested_table)
            
            # 4. ç”Ÿæˆæ ¼å¼åŒ–è¾“å‡º
            formatted_output = self._format_schema_output(tables, views)
            analysis_summary = self._generate_analysis_summary(tables, views, all_referenced_tables)
            
            self.log_info(f"è¡¨ç»“æ„åˆ†æå®Œæˆï¼šæ‰¾åˆ°{len(tables)}ä¸ªè¡¨ï¼Œ{len(views)}ä¸ªè§†å›¾")
            
            return SchemaAnalysisResult(
                tables=tables,
                views=views,
                all_referenced_tables=all_referenced_tables,
                formatted_output=formatted_output,
                analysis_summary=analysis_summary
            )
            
        except Exception as e:
            self.log_error("è¡¨ç»“æ„åˆ†æå¤±è´¥", error=e)
            return SchemaAnalysisResult(
                tables=[],
                views=[],
                all_referenced_tables=set(),
                formatted_output=f"åˆ†æå¤±è´¥: {str(e)}",
                analysis_summary=f"åˆ†æè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}"
            )
    
    def _extract_table_references(self, sql: str) -> List[str]:
        """æå–SQLè¯­å¥ä¸­çš„è¡¨åå¼•ç”¨"""
        try:
            # æ¸…ç†SQLè¯­å¥
            sql = re.sub(r'--.*$', '', sql, flags=re.MULTILINE)  # ç§»é™¤è¡Œæ³¨é‡Š
            sql = re.sub(r'/\*.*?\*/', '', sql, flags=re.DOTALL)  # ç§»é™¤å—æ³¨é‡Š
            
            table_references = []
            
            # ç®€åŒ–çš„è¡¨åæå–æ–¹æ³•
            # åŒ¹é… FROMã€JOINã€INTOã€UPDATEã€DELETE FROM åé¢çš„è¡¨å
            patterns = [
                r'FROM\s+(\[?[\w]+\]?(?:\.\[?[\w]+\]?(?:\.\[?[\w]+\]?)?)?)',
                r'JOIN\s+(\[?[\w]+\]?(?:\.\[?[\w]+\]?(?:\.\[?[\w]+\]?)?)?)',
                r'INTO\s+(\[?[\w]+\]?(?:\.\[?[\w]+\]?(?:\.\[?[\w]+\]?)?)?)',
                r'UPDATE\s+(\[?[\w]+\]?(?:\.\[?[\w]+\]?(?:\.\[?[\w]+\]?)?)?)',
                r'DELETE\s+FROM\s+(\[?[\w]+\]?(?:\.\[?[\w]+\]?(?:\.\[?[\w]+\]?)?)?)'
            ]
            
            for pattern in patterns:
                matches = re.findall(pattern, sql, re.IGNORECASE)
                for match in matches:
                    # æ¸…ç†æ–¹æ‹¬å·
                    clean_match = re.sub(r'[\[\]]', '', match)
                    if clean_match:
                        table_references.append(clean_match)
            
            # å»é‡
            return list(set(table_references))
            
        except Exception as e:
            self.log_error("æå–è¡¨åå¼•ç”¨å¤±è´¥", error=e)
            return []
    
    async def _get_table_info(self, table_ref: str, server_name: Optional[str] = None) -> Optional[TableInfo]:
        """è·å–è¡¨æˆ–è§†å›¾çš„è¯¦ç»†ä¿¡æ¯"""
        try:
            # è§£æè¡¨å
            parts = table_ref.split('.')
            if len(parts) == 3:
                database, schema, table = parts
            elif len(parts) == 2:
                database, schema, table = None, parts[0], parts[1]
            else:
                database, schema, table = None, 'dbo', parts[0]
            
            full_name = f"{database}.{schema}.{table}" if database else f"{schema}.{table}"
            
            # é˜²æ­¢é‡å¤åˆ†æ
            if full_name in self._analyzed_objects:
                return None
            self._analyzed_objects.add(full_name)
            
            # æŸ¥è¯¢å¯¹è±¡ä¿¡æ¯
            object_info_sql = f"""
            SELECT 
                o.name as object_name,
                s.name as schema_name,
                DB_NAME() as database_name,
                o.type_desc as object_type,
                CASE WHEN o.type = 'V' THEN 
                    OBJECT_DEFINITION(o.object_id) 
                ELSE NULL END as view_definition
            FROM sys.objects o
            JOIN sys.schemas s ON o.schema_id = s.schema_id
            WHERE o.name = '{table}' 
            AND s.name = '{schema}'
            AND o.type IN ('U', 'V')  -- ç”¨æˆ·è¡¨å’Œè§†å›¾
            """
            
            if database:
                object_info_sql = f"USE [{database}];\n" + object_info_sql
            
            object_info = await self._execute_query(object_info_sql, server_name)
            
            if not object_info:
                self.log_warning(f"æœªæ‰¾åˆ°è¡¨æˆ–è§†å›¾: {full_name}")
                return None
            
            obj_info = object_info[0]
            
            # è·å–åˆ—ä¿¡æ¯
            columns = await self._get_table_columns(database, schema, table, server_name)
            
            return TableInfo(
                name=obj_info['object_name'],
                schema=obj_info['schema_name'],
                database=obj_info['database_name'],
                full_name=f"{obj_info['database_name']}.{obj_info['schema_name']}.{obj_info['object_name']}",
                object_type='TABLE' if obj_info['object_type'] == 'USER_TABLE' else 'VIEW',
                columns=columns,
                view_definition=obj_info.get('view_definition'),
                referenced_tables=set()
            )
            
        except Exception as e:
            self.log_error(f"è·å–è¡¨ä¿¡æ¯å¤±è´¥: {table_ref}", error=e)
            return None
    
    async def _get_table_columns(self, database: Optional[str], schema: str, table: str, server_name: Optional[str] = None) -> List[Dict[str, Any]]:
        """è·å–è¡¨çš„åˆ—ä¿¡æ¯"""
        try:
            columns_sql = f"""
            SELECT 
                c.COLUMN_NAME as column_name,
                c.DATA_TYPE as data_type,
                c.CHARACTER_MAXIMUM_LENGTH as max_length,
                c.NUMERIC_PRECISION as precision,
                c.NUMERIC_SCALE as scale,
                c.IS_NULLABLE as is_nullable,
                c.COLUMN_DEFAULT as default_value,
                c.ORDINAL_POSITION as ordinal_position,
                CASE WHEN pk.COLUMN_NAME IS NOT NULL THEN 'YES' ELSE 'NO' END as is_primary_key
            FROM INFORMATION_SCHEMA.COLUMNS c
            LEFT JOIN (
                SELECT ku.TABLE_CATALOG, ku.TABLE_SCHEMA, ku.TABLE_NAME, ku.COLUMN_NAME
                FROM INFORMATION_SCHEMA.TABLE_CONSTRAINTS tc
                JOIN INFORMATION_SCHEMA.KEY_COLUMN_USAGE ku 
                    ON tc.CONSTRAINT_NAME = ku.CONSTRAINT_NAME
                WHERE tc.CONSTRAINT_TYPE = 'PRIMARY KEY'
            ) pk ON c.TABLE_CATALOG = pk.TABLE_CATALOG 
                AND c.TABLE_SCHEMA = pk.TABLE_SCHEMA 
                AND c.TABLE_NAME = pk.TABLE_NAME 
                AND c.COLUMN_NAME = pk.COLUMN_NAME
            WHERE c.TABLE_NAME = '{table}' 
            AND c.TABLE_SCHEMA = '{schema}'
            """
            
            if database:
                columns_sql = f"USE [{database}];\n" + columns_sql
                
            columns_sql += " ORDER BY c.ORDINAL_POSITION"
            
            return await self._execute_query(columns_sql, server_name)
            
        except Exception as e:
            self.log_error(f"è·å–åˆ—ä¿¡æ¯å¤±è´¥: {database}.{schema}.{table}", error=e)
            return []
    
    async def _analyze_view_dependencies(self, view_definition: str, server_name: Optional[str] = None) -> List[TableInfo]:
        """é€’å½’åˆ†æè§†å›¾å†…çš„è¡¨ä¾èµ–"""
        try:
            if not view_definition:
                return []
            
            # ä»è§†å›¾å®šä¹‰ä¸­æå–è¡¨å¼•ç”¨
            table_references = self._extract_table_references(view_definition)
            
            nested_tables = []
            for table_ref in table_references:
                table_info = await self._get_table_info(table_ref, server_name)
                if table_info:
                    nested_tables.append(table_info)
                    
                    # å¦‚æœæ˜¯è§†å›¾ï¼Œé€’å½’åˆ†æ
                    if table_info.object_type == 'VIEW' and table_info.view_definition:
                        deeper_tables = await self._analyze_view_dependencies(
                            table_info.view_definition, 
                            server_name
                        )
                        nested_tables.extend(deeper_tables)
            
            return nested_tables
            
        except Exception as e:
            self.log_error("åˆ†æè§†å›¾ä¾èµ–å¤±è´¥", error=e)
            return []
    
    def _format_schema_output(self, tables: List[TableInfo], views: List[TableInfo]) -> str:
        """æ ¼å¼åŒ–è¾“å‡ºè¡¨ç»“æ„ä¿¡æ¯"""
        output = []
        
        # æ·»åŠ åˆ†ææ‘˜è¦
        output.append("=" * 80)
        output.append("SQL è¡¨ç»“æ„åˆ†ææŠ¥å‘Š")
        output.append("=" * 80)
        output.append(f"åˆ†ææ—¶é—´: {self._get_current_time()}")
        output.append(f"å‘ç°è¡¨æ•°é‡: {len(tables)}")
        output.append(f"å‘ç°è§†å›¾æ•°é‡: {len(views)}")
        output.append("")
        
        # è¾“å‡ºè¡¨ç»“æ„
        if tables:
            output.append("ğŸ“‹ è¡¨ç»“æ„ä¿¡æ¯")
            output.append("-" * 40)
            for i, table in enumerate(tables, 1):
                output.append(f"\n{i}. {table.full_name} (è¡¨)")
                output.append(f"   æ•°æ®åº“: {table.database}")
                output.append(f"   æ¶æ„: {table.schema}")
                output.append(f"   è¡¨å: {table.name}")
                output.append(f"   åˆ—æ•°: {len(table.columns)}")
                output.append("")
                
                # åˆ—ä¿¡æ¯
                if table.columns:
                    output.append("   åˆ—ä¿¡æ¯:")
                    output.append("   " + "-" * 60)
                    output.append(f"   {'åˆ—å':<20} {'æ•°æ®ç±»å‹':<15} {'å¯ç©º':<5} {'ä¸»é”®':<5} {'é»˜è®¤å€¼':<15}")
                    output.append("   " + "-" * 60)
                    
                    for col in table.columns:
                        col_type = col['data_type']
                        if col['max_length'] and col['data_type'] in ['varchar', 'nvarchar', 'char', 'nchar']:
                            col_type += f"({col['max_length']})"
                        elif col['precision'] and col['data_type'] in ['decimal', 'numeric']:
                            col_type += f"({col['precision']},{col['scale'] or 0})"
                        
                        output.append(f"   {col['column_name']:<20} {col_type:<15} {col['is_nullable']:<5} {col['is_primary_key']:<5} {col['default_value'] or '':<15}")
                
                output.append("")
        
        # è¾“å‡ºè§†å›¾ç»“æ„
        if views:
            output.append("ğŸ‘ï¸ è§†å›¾ç»“æ„ä¿¡æ¯")
            output.append("-" * 40)
            for i, view in enumerate(views, 1):
                output.append(f"\n{i}. {view.full_name} (è§†å›¾)")
                output.append(f"   æ•°æ®åº“: {view.database}")
                output.append(f"   æ¶æ„: {view.schema}")
                output.append(f"   è§†å›¾å: {view.name}")
                output.append(f"   åˆ—æ•°: {len(view.columns)}")
                output.append("")
                
                # åˆ—ä¿¡æ¯
                if view.columns:
                    output.append("   åˆ—ä¿¡æ¯:")
                    output.append("   " + "-" * 60)
                    output.append(f"   {'åˆ—å':<20} {'æ•°æ®ç±»å‹':<15} {'å¯ç©º':<5} {'ä¸»é”®':<5} {'é»˜è®¤å€¼':<15}")
                    output.append("   " + "-" * 60)
                    
                    for col in view.columns:
                        col_type = col['data_type']
                        if col['max_length'] and col['data_type'] in ['varchar', 'nvarchar', 'char', 'nchar']:
                            col_type += f"({col['max_length']})"
                        elif col['precision'] and col['data_type'] in ['decimal', 'numeric']:
                            col_type += f"({col['precision']},{col['scale'] or 0})"
                        
                        output.append(f"   {col['column_name']:<20} {col_type:<15} {col['is_nullable']:<5} {col['is_primary_key']:<5} {col['default_value'] or '':<15}")
                
                # è§†å›¾å®šä¹‰
                if view.view_definition:
                    output.append("")
                    output.append("   è§†å›¾å®šä¹‰:")
                    output.append("   " + "-" * 40)
                    view_lines = view.view_definition.split('\n')
                    for line in view_lines[:10]:  # åªæ˜¾ç¤ºå‰10è¡Œ
                        output.append(f"   {line}")
                    if len(view_lines) > 10:
                        output.append(f"   ... (è¿˜æœ‰ {len(view_lines) - 10} è¡Œ)")
                
                output.append("")
        
        output.append("=" * 80)
        output.append("æŠ¥å‘Šç»“æŸ")
        output.append("=" * 80)
        
        return "\n".join(output)
    
    def _generate_analysis_summary(self, tables: List[TableInfo], views: List[TableInfo], all_referenced_tables: Set[str]) -> str:
        """ç”Ÿæˆåˆ†ææ‘˜è¦"""
        total_columns = sum(len(table.columns) for table in tables + views)
        
        summary = f"""
åˆ†ææ‘˜è¦:
- æ€»è®¡å‘ç° {len(all_referenced_tables)} ä¸ªæ•°æ®åº“å¯¹è±¡
- å…¶ä¸­è¡¨: {len(tables)} ä¸ª
- å…¶ä¸­è§†å›¾: {len(views)} ä¸ª  
- æ€»åˆ—æ•°: {total_columns} ä¸ª
- åˆ†ææ—¶é—´: {self._get_current_time()}
"""
        return summary.strip()
    
    def _get_current_time(self) -> str:
        """è·å–å½“å‰æ—¶é—´å­—ç¬¦ä¸²"""
        from datetime import datetime
        return datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    
    async def _execute_query(self, sql: str, server_name: Optional[str] = None) -> List[Dict[str, Any]]:
        """æ‰§è¡ŒSQLæŸ¥è¯¢"""
        try:
            if server_name:
                return await self.sqlserver.execute_query_with_server(server_name, sql)
            else:
                return await self.sqlserver.execute_query(sql)
        except Exception as e:
            self.log_error("æŸ¥è¯¢æ‰§è¡Œå¤±è´¥", error=e)
            return []


# å…¨å±€åˆ†æå™¨å®ä¾‹
_schema_analyzer: Optional[SchemaAnalyzer] = None


def get_schema_analyzer() -> SchemaAnalyzer:
    """è·å–å…¨å±€è¡¨ç»“æ„åˆ†æå™¨å®ä¾‹"""
    global _schema_analyzer
    if _schema_analyzer is None:
        _schema_analyzer = SchemaAnalyzer()
    return _schema_analyzer